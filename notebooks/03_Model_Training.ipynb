{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm # Progession bar\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Configuration settings\n",
    "data_dir = Path.cwd().parent / 'data'\n",
    "images_dir = data_dir / 'extracted_images' / 'images'\n",
    "metadata_dir = data_dir / 'Data_Entry_2017_v2020.csv'\n",
    "train_list_path = data_dir / 'train_val_list.txt'\n",
    "test_list_path = data_dir / 'test_list.txt'\n",
    "preprocessed_dir = data_dir / 'processed/'  # Directory to save processed embeddings\n",
    "\n",
    "preprocessed_dir.mkdir(parents=True,exist_ok=True)\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent / 'data'\n",
    "images_dir = data_dir / 'extracted_images' / 'images'\n",
    "metadata_dir = data_dir / 'Data_Entry_2017_v2020.csv'\n",
    "train_list_path = data_dir / 'train_val_list.txt'\n",
    "test_list_path = data_dir / 'test_list.txt'\n",
    "preprocessed_dir = data_dir / 'processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src') \n",
    "from model1 import JointLearningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del cuaderno\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from model1 import JointLearningModel\n",
    "from train import train_model\n",
    "from data_loader import ChestXray8Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),             # Redimensionar a 224x224\n",
    "    transforms.ToTensor(),                     # Convertir a tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalización\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = ChestXray8Dataset(\n",
    "    img_dir=images_dir, \n",
    "    metadata_file=metadata_dir, \n",
    "    split_file=train_list_path,\n",
    "    mode='train',  # Training mode\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create the DataLoader for training\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "# Inicializar el modelo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = JointLearningModel(num_clusters=14, embedding_dim=128, pretrained=True).to(device)\n",
    "\n",
    "# Definir optimizador y función de pérdida\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        embeddings, cluster_probs = model(images)\n",
    "\n",
    "        # Clustering requiere logits\n",
    "        loss = criterion(cluster_probs, labels.argmax(dim=1))  # one-hot\n",
    "\n",
    "        # Backward pass y optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marta_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
